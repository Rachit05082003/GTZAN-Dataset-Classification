{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Method 3: CNN + Multi-Head Attention (IMPROVED)\n",
                "\n",
                "**Improvements over original version:**\n",
                "- Enhanced CNN architecture with 4 convolutional blocks\n",
                "- ELU activation for smoother gradients\n",
                "- Progressive dropout (0.2 → 0.4) for better regularization\n",
                "- Optimized attention heads (8 heads, d_model=256)\n",
                "- Two-layer classification head (256 → 128 → 10)\n",
                "- Learning rate scheduler (ReduceLROnPlateau)\n",
                "- Increased early stopping patience (15 epochs)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import librosa\n",
                "import os\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Model\n",
                "from tensorflow.keras.layers import (\n",
                "    Input, Conv2D, BatchNormalization, MaxPooling2D,\n",
                "    GlobalAveragePooling2D, GlobalAveragePooling1D,\n",
                "    Dense, Dropout, TimeDistributed, Layer\n",
                ")\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Plot styling\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette('husl')\n",
                "\n",
                "# Reproducibility\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "print(f'TensorFlow version: {tf.__version__}')\n",
                "print(f'GPU Available: {len(tf.config.list_physical_devices(\"GPU\")) > 0}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset path\n",
                "DATA_PATH = '../../Data/genres_original'\n",
                "\n",
                "# Audio parameters\n",
                "SAMPLE_RATE = 22050\n",
                "N_FFT = 2048\n",
                "HOP_LENGTH = 512\n",
                "N_MELS = 64\n",
                "\n",
                "# Segmentation parameters\n",
                "TARGET_LENGTH = 1291  # frames\n",
                "SEGMENT_LENGTH = 87   # ~2 seconds\n",
                "NUM_SEGMENTS = 15\n",
                "OVERLAP = 0.75\n",
                "\n",
                "# Model parameters\n",
                "NUM_HEADS = 8\n",
                "D_MODEL = 256\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 100\n",
                "LEARNING_RATE = 0.001"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Loading Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_melspectrogram(audio_path, sr=22050, n_fft=2048, hop_length=512, n_mels=64):\n",
                "    \"\"\"\n",
                "    Extract mel-spectrogram from audio file.\n",
                "    \"\"\"\n",
                "    y, sr = librosa.load(audio_path, sr=sr, duration=30)\n",
                "    melspec = librosa.feature.melspectrogram(\n",
                "        y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels\n",
                "    )\n",
                "    melspec_db = librosa.power_to_db(melspec, ref=np.max)\n",
                "    return melspec_db\n",
                "\n",
                "def segment_spectrogram(melspec, segment_length=87, overlap=0.75, num_segments=15):\n",
                "    \"\"\"\n",
                "    Segment mel-spectrogram into overlapping 2-second segments.\n",
                "    \n",
                "    Args:\n",
                "        melspec: (64, 1291) mel-spectrogram\n",
                "        segment_length: 87 frames (~2 seconds)\n",
                "        overlap: 0.75 (75% overlap)\n",
                "        num_segments: 15 segments\n",
                "    \n",
                "    Returns:\n",
                "        (15, 87, 64) segmented array\n",
                "    \"\"\"\n",
                "    melspec = melspec.T  # (1291, 64)\n",
                "    hop = int(segment_length * (1 - overlap))\n",
                "    segments = []\n",
                "    \n",
                "    for i in range(0, melspec.shape[0] - segment_length + 1, hop):\n",
                "        segment = melspec[i:i+segment_length, :]\n",
                "        segments.append(segment)\n",
                "        if len(segments) >= num_segments:\n",
                "            break\n",
                "    \n",
                "    # Pad to exactly num_segments\n",
                "    while len(segments) < num_segments:\n",
                "        segments.append(np.zeros((segment_length, 64)))\n",
                "    \n",
                "    return np.array(segments[:num_segments])  # (15, 87, 64)\n",
                "\n",
                "def load_gtzan_segmented(data_path, target_length=1291):\n",
                "    \"\"\"\n",
                "    Load GTZAN dataset and create segmented mel-spectrograms.\n",
                "    \"\"\"\n",
                "    genres = ['blues', 'classical', 'country', 'disco', 'hiphop',\n",
                "              'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
                "    \n",
                "    features = []\n",
                "    labels = []\n",
                "    \n",
                "    print(\"Loading GTZAN dataset and creating segmented spectrograms...\")\n",
                "    for genre_idx, genre in enumerate(genres):\n",
                "        print(f\"Processing {genre}...\")\n",
                "        genre_path = os.path.join(data_path, genre)\n",
                "        files = [f for f in os.listdir(genre_path) if f.endswith('.wav')]\n",
                "        \n",
                "        for filename in tqdm(files, desc=f\"{genre}\"):\n",
                "            if filename == 'jazz.00054.wav':\n",
                "                print(f\"Skipping corrupted file: {filename}\")\n",
                "                continue\n",
                "            \n",
                "            filepath = os.path.join(genre_path, filename)\n",
                "            try:\n",
                "                melspec = extract_melspectrogram(filepath)\n",
                "                \n",
                "                # Pad or truncate to target length\n",
                "                if melspec.shape[1] < target_length:\n",
                "                    pad_width = target_length - melspec.shape[1]\n",
                "                    melspec = np.pad(melspec, ((0, 0), (0, pad_width)), mode='constant')\n",
                "                else:\n",
                "                    melspec = melspec[:, :target_length]\n",
                "                \n",
                "                # Segment into 15 overlapping segments\n",
                "                segments = segment_spectrogram(melspec)\n",
                "                features.append(segments)\n",
                "                labels.append(genre_idx)\n",
                "            except Exception as e:\n",
                "                print(f\"Error processing {filepath}: {e}\")\n",
                "    \n",
                "    return np.array(features), np.array(labels), genres"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load dataset\n",
                "X, y, genre_names = load_gtzan_segmented(DATA_PATH)\n",
                "\n",
                "print(f\"\\n✓ Dataset loaded\")\n",
                "print(f\"  Features shape: {X.shape}\")  # (999, 15, 87, 64)\n",
                "print(f\"  Labels shape: {y.shape}\")    # (999,)\n",
                "print(f\"  Genres: {genre_names}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Train/Val/Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split: 70% train, 15% val, 15% test\n",
                "X_train, X_temp, y_train, y_temp = train_test_split(\n",
                "    X, y, test_size=0.3, random_state=42, stratify=y\n",
                ")\n",
                "X_val, X_test, y_val, y_test = train_test_split(\n",
                "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
                ")\n",
                "\n",
                "print(f\"Train: {X_train.shape[0]} samples\")\n",
                "print(f\"Val:   {X_val.shape[0]} samples\")\n",
                "print(f\"Test:  {X_test.shape[0]} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Normalize Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reshape for normalization\n",
                "X_train_flat = X_train.reshape(-1, 87*64)\n",
                "X_val_flat = X_val.reshape(-1, 87*64)\n",
                "X_test_flat = X_test.reshape(-1, 87*64)\n",
                "\n",
                "# Normalize\n",
                "scaler = StandardScaler()\n",
                "X_train_norm = scaler.fit_transform(X_train_flat).reshape(X_train.shape)\n",
                "X_val_norm = scaler.transform(X_val_flat).reshape(X_val.shape)\n",
                "X_test_norm = scaler.transform(X_test_flat).reshape(X_test.shape)\n",
                "\n",
                "# Add channel dimension\n",
                "X_train_norm = X_train_norm[..., np.newaxis]  # (n, 15, 87, 64, 1)\n",
                "X_val_norm = X_val_norm[..., np.newaxis]\n",
                "X_test_norm = X_test_norm[..., np.newaxis]\n",
                "\n",
                "# One-hot encode labels\n",
                "y_train = to_categorical(y_train, 10)\n",
                "y_val = to_categorical(y_val, 10)\n",
                "y_test = to_categorical(y_test, 10)\n",
                "\n",
                "print(\"✓ Data normalized and encoded\")\n",
                "print(f\"  X_train shape: {X_train_norm.shape}\")\n",
                "print(f\"  y_train shape: {y_train.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Multi-Head Attention Layer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MultiHeadAttention(Layer):\n",
                "    \"\"\"\n",
                "    Multi-head attention layer for temporal weighting.\n",
                "    \"\"\"\n",
                "    def __init__(self, num_heads=8, d_model=128, **kwargs):\n",
                "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
                "        self.num_heads = num_heads\n",
                "        self.d_model = d_model\n",
                "        self.depth = d_model // num_heads\n",
                "        \n",
                "        self.wq = Dense(d_model)\n",
                "        self.wk = Dense(d_model)\n",
                "        self.wv = Dense(d_model)\n",
                "        self.dense = Dense(d_model)\n",
                "    \n",
                "    def split_heads(self, x, batch_size):\n",
                "        \"\"\"Split the last dimension into (num_heads, depth)\"\"\"\n",
                "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
                "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
                "    \n",
                "    def call(self, inputs):\n",
                "        batch_size = tf.shape(inputs)[0]\n",
                "        \n",
                "        # Linear projections\n",
                "        q = self.wq(inputs)\n",
                "        k = self.wk(inputs)\n",
                "        v = self.wv(inputs)\n",
                "        \n",
                "        # Split into multiple heads\n",
                "        q = self.split_heads(q, batch_size)\n",
                "        k = self.split_heads(k, batch_size)\n",
                "        v = self.split_heads(v, batch_size)\n",
                "        \n",
                "        # Scaled dot-product attention\n",
                "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
                "        dk = tf.cast(self.depth, tf.float32)\n",
                "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
                "        \n",
                "        # Attention weights\n",
                "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
                "        \n",
                "        # Apply attention to values\n",
                "        output = tf.matmul(attention_weights, v)\n",
                "        \n",
                "        # Concatenate heads\n",
                "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
                "        output = tf.reshape(output, (batch_size, -1, self.d_model))\n",
                "        \n",
                "        # Final linear projection\n",
                "        output = self.dense(output)\n",
                "        \n",
                "        return output, attention_weights"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Improved CNN Feature Extractor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_cnn_feature_extractor():\n",
                "    \"\"\"\n",
                "    Build improved CNN to extract features from each 2-second segment.\n",
                "    Input: (87, 64, 1)\n",
                "    Output: (256,) feature vector\n",
                "    \n",
                "    Improvements:\n",
                "    - 4 convolutional blocks (32→64→128→256 filters)\n",
                "    - ELU activation for smoother gradients\n",
                "    - Batch normalization after each conv\n",
                "    - Progressive dropout (0.2 → 0.4)\n",
                "    \"\"\"\n",
                "    inputs = Input(shape=(87, 64, 1))\n",
                "    \n",
                "    # Conv Block 1\n",
                "    x = Conv2D(32, (3, 3), padding='same', activation='elu')(inputs)\n",
                "    x = BatchNormalization()(x)\n",
                "    x = MaxPooling2D((2, 2))(x)\n",
                "    x = Dropout(0.2)(x)\n",
                "    \n",
                "    # Conv Block 2\n",
                "    x = Conv2D(64, (3, 3), padding='same', activation='elu')(x)\n",
                "    x = BatchNormalization()(x)\n",
                "    x = MaxPooling2D((2, 2))(x)\n",
                "    x = Dropout(0.2)(x)\n",
                "    \n",
                "    # Conv Block 3\n",
                "    x = Conv2D(128, (3, 3), padding='same', activation='elu')(x)\n",
                "    x = BatchNormalization()(x)\n",
                "    x = MaxPooling2D((2, 2))(x)\n",
                "    x = Dropout(0.3)(x)\n",
                "    \n",
                "    # Conv Block 4 (final)\n",
                "    x = Conv2D(256, (3, 3), padding='same', activation='elu')(x)\n",
                "    x = BatchNormalization()(x)\n",
                "    x = GlobalAveragePooling2D()(x)\n",
                "    x = Dropout(0.4)(x)\n",
                "    \n",
                "    model = Model(inputs, x, name='cnn_feature_extractor')\n",
                "    return model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Build CNN + Attention Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_cnn_attention_model():\n",
                "    \"\"\"\n",
                "    Build improved CNN + Multi-Head Attention model.\n",
                "    \n",
                "    Architecture:\n",
                "    - CNN feature extractor (TimeDistributed)\n",
                "    - Multi-head attention (8 heads, d_model=256)\n",
                "    - Global average pooling\n",
                "    - Two-layer dense classifier (256→128→10)\n",
                "    \"\"\"\n",
                "    segment_input = Input(shape=(15, 87, 64, 1), name='segment_input')\n",
                "    \n",
                "    # Apply CNN to each segment independently\n",
                "    cnn_extractor = build_cnn_feature_extractor()\n",
                "    cnn_features = TimeDistributed(cnn_extractor, name='time_distributed_cnn')(segment_input)\n",
                "    \n",
                "    # Multi-head attention (8 heads, d_model=256)\n",
                "    attn_layer = MultiHeadAttention(num_heads=8, d_model=256, name='multi_head_attention')\n",
                "    attn_output, attn_weights = attn_layer(cnn_features)\n",
                "    \n",
                "    # Global pooling over temporal dimension\n",
                "    x = GlobalAveragePooling1D(name='global_avgpool')(attn_output)\n",
                "    \n",
                "    # Classification head\n",
                "    x = Dense(256, activation='elu', name='dense_1')(x)\n",
                "    x = Dropout(0.5, name='dropout_1')(x)\n",
                "    x = Dense(128, activation='elu', name='dense_2')(x)\n",
                "    x = Dropout(0.3, name='dropout_2')(x)\n",
                "    outputs = Dense(10, activation='softmax', name='output')(x)\n",
                "    \n",
                "    # Build model\n",
                "    model = Model(segment_input, outputs, name='cnn_attention_model_improved')\n",
                "    \n",
                "    # Compile\n",
                "    model.compile(\n",
                "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
                "        loss='categorical_crossentropy',\n",
                "        metrics=['accuracy']\n",
                "    )\n",
                "    \n",
                "    return model\n",
                "\n",
                "# Build model\n",
                "model = build_cnn_attention_model()\n",
                "\n",
                "# Display model architecture\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Callbacks\n",
                "early_stop = EarlyStopping(\n",
                "    monitor='val_loss',\n",
                "    patience=15,\n",
                "    restore_best_weights=True,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "reduce_lr = ReduceLROnPlateau(\n",
                "    monitor='val_loss',\n",
                "    factor=0.5,\n",
                "    patience=5,\n",
                "    min_lr=1e-6,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "# Train model\n",
                "history = model.fit(\n",
                "    X_train_norm, y_train,\n",
                "    validation_data=(X_val_norm, y_val),\n",
                "    batch_size=32,\n",
                "    epochs=100,\n",
                "    callbacks=[early_stop, reduce_lr],\n",
                "    verbose=1\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Training History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training history\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Loss\n",
                "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
                "axes[0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
                "axes[0].set_xlabel('Epoch', fontsize=12)\n",
                "axes[0].set_ylabel('Loss', fontsize=12)\n",
                "axes[0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Accuracy\n",
                "axes[1].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
                "axes[1].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
                "axes[1].set_xlabel('Epoch', fontsize=12)\n",
                "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
                "axes[1].set_title('Training & Validation Accuracy', fontsize=14, fontweight='bold')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('cnn_attention_improved_training_history.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate on test set\n",
                "test_loss, test_acc = model.evaluate(X_test_norm, y_test, verbose=0)\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
                "print(f\"Test Loss: {test_loss:.4f}\")\n",
                "print(f\"{'='*50}\\n\")\n",
                "\n",
                "# Predictions\n",
                "y_pred = model.predict(X_test_norm, verbose=0)\n",
                "y_pred_labels = np.argmax(y_pred, axis=1)\n",
                "y_true_labels = np.argmax(y_test, axis=1)\n",
                "\n",
                "# Classification report\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_true_labels, y_pred_labels, target_names=genre_names))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion matrix\n",
                "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
                "\n",
                "plt.figure(figsize=(12, 10))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "            xticklabels=genre_names, yticklabels=genre_names,\n",
                "            cbar_kws={'label': 'Count'})\n",
                "plt.xlabel('Predicted Genre', fontsize=12, fontweight='bold')\n",
                "plt.ylabel('True Genre', fontsize=12, fontweight='bold')\n",
                "plt.title('CNN + Attention (Improved) - Confusion Matrix', fontsize=14, fontweight='bold')\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.yticks(rotation=0)\n",
                "plt.tight_layout()\n",
                "plt.savefig('cnn_attention_improved_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 14. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model\n",
                "model.save('cnn_attention_improved.keras')\n",
                "print(\"✓ Model saved: cnn_attention_improved.keras\")\n",
                "\n",
                "# Save training history\n",
                "np.save('cnn_attention_improved_history.npy', history.history)\n",
                "print(\"✓ Training history saved: cnn_attention_improved_history.npy\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "This improved CNN + Multi-Head Attention model includes:\n",
                "\n",
                "**Architecture Improvements:**\n",
                "- 4-block CNN feature extractor (32→64→128→256 filters)\n",
                "- ELU activation functions for smoother gradients\n",
                "- Batch normalization after each convolution\n",
                "- Progressive dropout (0.2 → 0.4) for regularization\n",
                "- 8-head attention mechanism with d_model=256\n",
                "- Two-layer classification head (256→128→10)\n",
                "\n",
                "**Training Improvements:**\n",
                "- Learning rate scheduler (ReduceLROnPlateau)\n",
                "- Increased early stopping patience (15 epochs)\n",
                "- Adam optimizer with initial LR=0.001\n",
                "\n",
                "**Expected Performance:**\n",
                "- Target accuracy: 70-85% (significant improvement over baseline 64%)\n",
                "- Better generalization through enhanced regularization\n",
                "- More stable training with learning rate scheduling"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "gtzan",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.25"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}