{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CNN + Multi-Head Attention for Music Genre Classification\n",
                "\n",
                "**GTZAN Dataset - Improved & Bug-Free Implementation**\n",
                "\n",
                "This notebook implements a state-of-the-art CNN + Attention model with:\n",
                "- Multi-head self-attention mechanism\n",
                "- Data augmentation (SpecAugment)\n",
                "- Advanced CNN architecture with residual connections\n",
                "- Learning rate scheduling\n",
                "- Proper path handling"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports and Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import librosa\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, Model, regularizers\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Set seeds for reproducibility\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "# Plot styling\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette('husl')\n",
                "\n",
                "print(f\"TensorFlow version: {tf.__version__}\")\n",
                "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== PATHS ====================\n",
                "# Automatically detect the correct path\n",
                "BASE_DIR = os.path.dirname(os.getcwd())\n",
                "DATA_PATH = os.path.join(BASE_DIR, 'Data', 'genres_original')\n",
                "\n",
                "# Verify path\n",
                "if not os.path.exists(DATA_PATH):\n",
                "    # Try alternative path\n",
                "    DATA_PATH = '../../Data/genres_original'\n",
                "    if not os.path.exists(DATA_PATH):\n",
                "        raise FileNotFoundError(f\"Data not found. Please update DATA_PATH variable.\")\n",
                "\n",
                "print(f\"Data path: {DATA_PATH}\")\n",
                "print(f\"Path exists: {os.path.exists(DATA_PATH)}\")\n",
                "\n",
                "# ==================== AUDIO PARAMETERS ====================\n",
                "SAMPLE_RATE = 22050\n",
                "DURATION = 30\n",
                "N_MELS = 128\n",
                "N_FFT = 2048\n",
                "HOP_LENGTH = 512\n",
                "\n",
                "# ==================== SEGMENTATION ====================\n",
                "NUM_SEGMENTS = 15  # 15 x 2-second segments\n",
                "\n",
                "# ==================== MODEL ====================\n",
                "NUM_CLASSES = 10\n",
                "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop',\n",
                "          'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
                "\n",
                "# ==================== HYPERPARAMETERS ====================\n",
                "CNN_FILTERS = [32, 64, 128, 256]\n",
                "ATTENTION_HEADS = 8\n",
                "KEY_DIM = 32\n",
                "DENSE_UNITS = 256\n",
                "DROPOUT_RATE = 0.4\n",
                "L2_REG = 0.0005\n",
                "LEARNING_RATE = 0.001\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 100"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Verify Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nDataset verification:\")\n",
                "print(\"=\" * 50)\n",
                "total_files = 0\n",
                "for genre in GENRES:\n",
                "    genre_path = os.path.join(DATA_PATH, genre)\n",
                "    if os.path.exists(genre_path):\n",
                "        files = [f for f in os.listdir(genre_path) if f.endswith('.wav')]\n",
                "        count = len(files)\n",
                "        total_files += count\n",
                "        print(f\"  {genre:12s}: {count:3d} files\")\n",
                "    else:\n",
                "        print(f\"  {genre:12s}: NOT FOUND\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Total: {total_files} files\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Extraction with SpecAugment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def spec_augment(mel, time_mask_param=10, freq_mask_param=8, augment=True):\n",
                "    \"\"\"Apply SpecAugment for data augmentation.\"\"\"\n",
                "    if not augment:\n",
                "        return mel\n",
                "    \n",
                "    mel = mel.copy()\n",
                "    \n",
                "    # Time masking\n",
                "    if mel.shape[1] > time_mask_param:\n",
                "        t = np.random.randint(0, mel.shape[1] - time_mask_param)\n",
                "        mel[:, t:t+time_mask_param] = 0\n",
                "    \n",
                "    # Frequency masking\n",
                "    if mel.shape[0] > freq_mask_param:\n",
                "        f = np.random.randint(0, mel.shape[0] - freq_mask_param)\n",
                "        mel[f:f+freq_mask_param, :] = 0\n",
                "    \n",
                "    return mel\n",
                "\n",
                "\n",
                "def extract_melspectrogram(audio_path, augment=False):\n",
                "    \"\"\"Extract mel-spectrogram from audio file.\"\"\"\n",
                "    try:\n",
                "        # Load audio\n",
                "        audio, _ = librosa.load(audio_path, sr=SAMPLE_RATE, duration=DURATION)\n",
                "        \n",
                "        # Pad or trim to exact length\n",
                "        target_len = SAMPLE_RATE * DURATION\n",
                "        if len(audio) < target_len:\n",
                "            audio = np.pad(audio, (0, target_len - len(audio)))\n",
                "        else:\n",
                "            audio = audio[:target_len]\n",
                "        \n",
                "        # Extract mel-spectrogram\n",
                "        mel = librosa.feature.melspectrogram(\n",
                "            y=audio,\n",
                "            sr=SAMPLE_RATE,\n",
                "            n_mels=N_MELS,\n",
                "            n_fft=N_FFT,\n",
                "            hop_length=HOP_LENGTH\n",
                "        )\n",
                "        \n",
                "        # Convert to dB\n",
                "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
                "        \n",
                "        # Apply SpecAugment\n",
                "        mel_db = spec_augment(mel_db, augment=augment)\n",
                "        \n",
                "        return mel_db\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Error loading {audio_path}: {str(e)}\")\n",
                "        return None\n",
                "\n",
                "\n",
                "def create_segments(mel_spec, num_segments=NUM_SEGMENTS):\n",
                "    \"\"\"Split mel-spectrogram into equal segments.\"\"\"\n",
                "    n_frames = mel_spec.shape[1]\n",
                "    seg_len = n_frames // num_segments\n",
                "    \n",
                "    segments = []\n",
                "    for i in range(num_segments):\n",
                "        start = i * seg_len\n",
                "        end = start + seg_len\n",
                "        if end > n_frames:\n",
                "            end = n_frames\n",
                "        seg = mel_spec[:, start:end]\n",
                "        \n",
                "        # Pad if needed\n",
                "        if seg.shape[1] < seg_len:\n",
                "            seg = np.pad(seg, ((0, 0), (0, seg_len - seg.shape[1])))\n",
                "        \n",
                "        segments.append(seg)\n",
                "    \n",
                "    return np.array(segments)\n",
                "\n",
                "print(\"Feature extraction functions defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(data_path, augment=False):\n",
                "    \"\"\"Load GTZAN dataset and extract features.\"\"\"\n",
                "    X, y = [], []\n",
                "    \n",
                "    print(\"Loading dataset...\\n\")\n",
                "    for genre_idx, genre in enumerate(GENRES):\n",
                "        genre_path = os.path.join(data_path, genre)\n",
                "        \n",
                "        if not os.path.exists(genre_path):\n",
                "            print(f\"Warning: {genre} folder not found\")\n",
                "            continue\n",
                "        \n",
                "        files = sorted([f for f in os.listdir(genre_path) if f.endswith('.wav')])\n",
                "        \n",
                "        print(f\"Processing {genre} ({len(files)} files)...\")\n",
                "        \n",
                "        for filename in tqdm(files, desc=genre):\n",
                "            # Skip known corrupted file\n",
                "            if filename == 'jazz.00054.wav':\n",
                "                print(f\"  Skipping corrupted file: {filename}\")\n",
                "                continue\n",
                "            \n",
                "            filepath = os.path.join(genre_path, filename)\n",
                "            \n",
                "            # Extract features\n",
                "            mel = extract_melspectrogram(filepath, augment=augment)\n",
                "            \n",
                "            if mel is not None:\n",
                "                segments = create_segments(mel)\n",
                "                X.append(segments)\n",
                "                y.append(genre_idx)\n",
                "    \n",
                "    X = np.array(X)\n",
                "    y = np.array(y)\n",
                "    \n",
                "    print(f\"\\nLoaded {len(X)} samples\")\n",
                "    print(f\"Shape: {X.shape}\")\n",
                "    \n",
                "    return X, y\n",
                "\n",
                "# Load data\n",
                "X, y = load_data(DATA_PATH, augment=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encode labels\n",
                "label_encoder = LabelEncoder()\n",
                "y_encoded = label_encoder.fit_transform(y)\n",
                "y_onehot = to_categorical(y_encoded, NUM_CLASSES)\n",
                "\n",
                "# Add channel dimension\n",
                "X = X[..., np.newaxis]\n",
                "\n",
                "print(f\"X shape: {X.shape}\")\n",
                "print(f\"y shape: {y_onehot.shape}\")\n",
                "print(f\"Genre mapping: {dict(enumerate(GENRES))}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Train/Val/Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split: 80% train, 10% val, 10% test\n",
                "X_temp, X_test, y_temp, y_test = train_test_split(\n",
                "    X, y_onehot, test_size=0.1, stratify=y_encoded, random_state=42\n",
                ")\n",
                "\n",
                "y_temp_enc = np.argmax(y_temp, axis=1)\n",
                "X_train, X_val, y_train, y_val = train_test_split(\n",
                "    X_temp, y_temp, test_size=0.111, stratify=y_temp_enc, random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Train: {X_train.shape[0]} samples\")\n",
                "print(f\"Val:   {X_val.shape[0]} samples\")\n",
                "print(f\"Test:  {X_test.shape[0]} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Normalization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute normalization stats from training data\n",
                "train_mean = X_train.mean()\n",
                "train_std = X_train.std()\n",
                "\n",
                "# Normalize all sets\n",
                "X_train = (X_train - train_mean) / (train_std + 1e-8)\n",
                "X_val = (X_val - train_mean) / (train_std + 1e-8)\n",
                "X_test = (X_test - train_mean) / (train_std + 1e-8)\n",
                "\n",
                "print(f\"Normalization - Mean: {train_mean:.2f}, Std: {train_std:.2f}\")\n",
                "print(f\"After norm - Mean: {X_train.mean():.4f}, Std: {X_train.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Build CNN + Multi-Head Attention Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_cnn_attention_model(input_shape):\n",
                "    \"\"\"\n",
                "    Build CNN + Multi-Head Attention model.\n",
                "    \n",
                "    Architecture:\n",
                "    1. TimeDistributed CNN (processes each segment)\n",
                "    2. Multi-Head Self-Attention (learns temporal relationships)\n",
                "    3. Global pooling + dense classifier\n",
                "    \"\"\"\n",
                "    \n",
                "    num_segments = input_shape[0]\n",
                "    segment_shape = input_shape[1:]\n",
                "    \n",
                "    # ==================== SEGMENT CNN ====================\n",
                "    seg_input = layers.Input(shape=segment_shape)\n",
                "    x = seg_input\n",
                "    \n",
                "    # CNN blocks with increasing filters\n",
                "    for i, filters in enumerate(CNN_FILTERS):\n",
                "        x = layers.Conv2D(\n",
                "            filters, 3, padding='same',\n",
                "            kernel_regularizer=regularizers.l2(L2_REG)\n",
                "        )(x)\n",
                "        x = layers.BatchNormalization()(x)\n",
                "        x = layers.Activation('elu')(x)\n",
                "        x = layers.MaxPooling2D(2)(x)\n",
                "        x = layers.Dropout(0.25)(x)\n",
                "    \n",
                "    # Global pooling\n",
                "    x = layers.GlobalAveragePooling2D()(x)\n",
                "    \n",
                "    segment_cnn = Model(seg_input, x, name='segment_cnn')\n",
                "    \n",
                "    # ==================== FULL MODEL ====================\n",
                "    inputs = layers.Input(shape=input_shape, name='input')\n",
                "    \n",
                "    # Apply CNN to each segment\n",
                "    features = layers.TimeDistributed(segment_cnn, name='time_distributed_cnn')(inputs)\n",
                "    \n",
                "    # Multi-Head Self-Attention\n",
                "    attn_output = layers.MultiHeadAttention(\n",
                "        num_heads=ATTENTION_HEADS,\n",
                "        key_dim=KEY_DIM,\n",
                "        dropout=0.1,\n",
                "        name='multi_head_attention'\n",
                "    )(features, features)  # Self-attention\n",
                "    \n",
                "    # Global pooling over temporal dimension\n",
                "    x = layers.GlobalAveragePooling1D(name='global_pool')(attn_output)\n",
                "    \n",
                "    # Classification head\n",
                "    x = layers.Dense(\n",
                "        DENSE_UNITS,\n",
                "        kernel_regularizer=regularizers.l2(L2_REG)\n",
                "    )(x)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    x = layers.Activation('elu')(x)\n",
                "    x = layers.Dropout(DROPOUT_RATE)(x)\n",
                "    \n",
                "    x = layers.Dense(\n",
                "        DENSE_UNITS // 2,\n",
                "        kernel_regularizer=regularizers.l2(L2_REG)\n",
                "    )(x)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    x = layers.Activation('elu')(x)\n",
                "    x = layers.Dropout(DROPOUT_RATE)(x)\n",
                "    \n",
                "    # Output\n",
                "    outputs = layers.Dense(NUM_CLASSES, activation='softmax', name='output')(x)\n",
                "    \n",
                "    # Build and compile\n",
                "    model = Model(inputs, outputs, name='cnn_multihead_attention')\n",
                "    \n",
                "    model.compile(\n",
                "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
                "        loss='categorical_crossentropy',\n",
                "        metrics=['accuracy']\n",
                "    )\n",
                "    \n",
                "    return model, segment_cnn\n",
                "\n",
                "\n",
                "# Build model\n",
                "input_shape = X_train.shape[1:]\n",
                "print(f\"Input shape: {input_shape}\\n\")\n",
                "\n",
                "model, segment_cnn = build_cnn_attention_model(input_shape)\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Callbacks\n",
                "callbacks = [\n",
                "    EarlyStopping(\n",
                "        monitor='val_accuracy',\n",
                "        patience=20,\n",
                "        restore_best_weights=True,\n",
                "        verbose=1\n",
                "    ),\n",
                "    ReduceLROnPlateau(\n",
                "        monitor='val_loss',\n",
                "        factor=0.5,\n",
                "        patience=7,\n",
                "        min_lr=1e-6,\n",
                "        verbose=1\n",
                "    ),\n",
                "    ModelCheckpoint(\n",
                "        'best_cnn_attention.keras',\n",
                "        monitor='val_accuracy',\n",
                "        save_best_only=True,\n",
                "        verbose=1\n",
                "    )\n",
                "]\n",
                "\n",
                "# Train\n",
                "print(\"\\nStarting training...\\n\")\n",
                "history = model.fit(\n",
                "    X_train, y_train,\n",
                "    validation_data=(X_val, y_val),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    epochs=EPOCHS,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Training History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training curves\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Accuracy\n",
                "ax1.plot(history.history['accuracy'], label='Train', linewidth=2)\n",
                "ax1.plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
                "ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
                "ax1.set_xlabel('Epoch')\n",
                "ax1.set_ylabel('Accuracy')\n",
                "ax1.legend()\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "# Loss\n",
                "ax2.plot(history.history['loss'], label='Train', linewidth=2)\n",
                "ax2.plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
                "ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
                "ax2.set_xlabel('Epoch')\n",
                "ax2.set_ylabel('Loss')\n",
                "ax2.legend()\n",
                "ax2.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "# Best metrics\n",
                "best_val_acc = max(history.history['val_accuracy'])\n",
                "best_epoch = history.history['val_accuracy'].index(best_val_acc) + 1\n",
                "print(f\"\\nBest Validation Accuracy: {best_val_acc:.4f} (Epoch {best_epoch})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "model.load_weights('best_cnn_attention.keras')\n",
                "\n",
                "# Evaluate on test set\n",
                "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(f\"TEST ACCURACY: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
                "print(f\"TEST LOSS: {test_loss:.4f}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Classification Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predictions\n",
                "y_pred = model.predict(X_test, verbose=0)\n",
                "y_pred_labels = np.argmax(y_pred, axis=1)\n",
                "y_true_labels = np.argmax(y_test, axis=1)\n",
                "\n",
                "# Classification report\n",
                "print(\"\\nClassification Report:\")\n",
                "print(\"=\" * 60)\n",
                "print(classification_report(\n",
                "    y_true_labels,\n",
                "    y_pred_labels,\n",
                "    target_names=GENRES,\n",
                "    digits=3\n",
                "))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 14. Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion matrix\n",
                "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
                "\n",
                "plt.figure(figsize=(12, 10))\n",
                "sns.heatmap(\n",
                "    cm, annot=True, fmt='d', cmap='Blues',\n",
                "    xticklabels=GENRES, yticklabels=GENRES,\n",
                "    cbar_kws={'label': 'Count'}\n",
                ")\n",
                "plt.xlabel('Predicted Genre', fontsize=12, fontweight='bold')\n",
                "plt.ylabel('True Genre', fontsize=12, fontweight='bold')\n",
                "plt.title(f'Confusion Matrix (Accuracy: {test_acc:.2%})', fontsize=14, fontweight='bold')\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.yticks(rotation=0)\n",
                "plt.tight_layout()\n",
                "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 15. Save Model and Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save final model\n",
                "model.save('cnn_attention_final.keras')\n",
                "\n",
                "# Save normalization parameters\n",
                "np.savez('normalization_params.npz', mean=train_mean, std=train_std)\n",
                "\n",
                "# Save training history\n",
                "np.save('training_history.npy', history.history)\n",
                "\n",
                "print(\"\\nSaved files:\")\n",
                "print(\"  ✓ cnn_attention_final.keras\")\n",
                "print(\"  ✓ best_cnn_attention.keras\")\n",
                "print(\"  ✓ normalization_params.npz\")\n",
                "print(\"  ✓ training_history.npy\")\n",
                "print(\"  ✓ training_history.png\")\n",
                "print(\"  ✓ confusion_matrix.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "This notebook implements a CNN + Multi-Head Attention model for music genre classification:\n",
                "\n",
                "**Key Features:**\n",
                "- 15 temporal segments (2 seconds each)\n",
                "- 4-layer CNN feature extractor per segment\n",
                "- 8-head self-attention mechanism\n",
                "- SpecAugment data augmentation\n",
                "- Learning rate scheduling\n",
                "- Early stopping with best weight restoration\n",
                "\n",
                "**Architecture:**\n",
                "```\n",
                "Input (15 segments) \n",
                "  → TimeDistributed CNN (32→64→128→256 filters)\n",
                "  → Multi-Head Attention (8 heads)\n",
                "  → Global Pool\n",
                "  → Dense (256→128)\n",
                "  → Output (10 genres)\n",
                "```\n",
                "\n",
                "**Expected Performance:**\n",
                "- Target accuracy: 75-85% on test set\n",
                "- Attention mechanism learns which temporal segments are most discriminative for each genre\n",
                "\n",
                "**Next Steps:**\n",
                "- Try different numbers of segments (10, 20)\n",
                "- Experiment with attention heads (4, 16)\n",
                "- Add more data augmentation\n",
                "- Fine-tune hyperparameters"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "gtzan",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.25"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}