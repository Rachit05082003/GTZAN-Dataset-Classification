{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Method 1: Kaggle LSTM Implementation\n",
                "\n",
                "**Reference**: [Kaggle Notebook](https://www.kaggle.com/code/gtessier/lstm-implementation-grad)\n",
                "\n",
                "**Architecture**:\n",
                "- Input: 13 MFCC coefficients\n",
                "- Reshaping: `(N, 13, 1)` - Treating the 13 coefficients as time steps.\n",
                "- Model:\n",
                "    - LSTM(64, return_sequences=True)\n",
                "    - LSTM(64)\n",
                "    - Dense(64, activation='relu')\n",
                "    - Dropout(0.3)\n",
                "    - Dense(10, activation='softmax')\n",
                "\n",
                "**Improvement**:\n",
                "- We use **Song-ID based splitting** instead of random splitting to strictly prevent data leakage."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "from sklearn.model_selection import GroupShuffleSplit\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.metrics import classification_report, accuracy_score\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "print(f'TensorFlow version: {tf.__version__}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data & Select MFCC Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('../data/gtzan/features_3_sec.csv')\n",
                "\n",
                "# Extract Song ID for grouping\n",
                "df['song_id'] = df['filename'].apply(lambda x: '.'.join(x.split('.')[:2]))\n",
                "\n",
                "# Select ONLY the first 13 MFCC mean features to match reference\n",
                "mfcc_cols = [f'mfcc{i}_mean' for i in range(1, 14)]\n",
                "print(f\"Selected Features: {mfcc_cols}\")\n",
                "\n",
                "X = df[mfcc_cols]\n",
                "y = df['label']\n",
                "groups = df['song_id']\n",
                "\n",
                "# Encode labels\n",
                "label_encoder = LabelEncoder()\n",
                "y_encoded = label_encoder.fit_transform(y)\n",
                "num_classes = len(label_encoder.classes_)\n",
                "y_cat = to_categorical(y_encoded, num_classes)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Train/Test Split (Grouped by Song)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split: 70% Train, 15% Val, 15% Test\n",
                "splitter_outer = GroupShuffleSplit(test_size=0.30, n_splits=1, random_state=42)\n",
                "train_idx, temp_idx = next(splitter_outer.split(X, y, groups))\n",
                "\n",
                "X_train, X_temp = X.iloc[train_idx], X.iloc[temp_idx]\n",
                "y_train, y_temp = y_cat[train_idx], y_cat[temp_idx]\n",
                "groups_temp = groups.iloc[temp_idx]\n",
                "\n",
                "splitter_inner = GroupShuffleSplit(test_size=0.50, n_splits=1, random_state=42)\n",
                "val_idx, test_idx = next(splitter_inner.split(X_temp, y_temp, groups_temp))\n",
                "\n",
                "X_val, X_test = X_temp.iloc[val_idx], X_temp.iloc[test_idx]\n",
                "y_val, y_test = y_temp[val_idx], y_temp[test_idx]\n",
                "groups_test = groups_temp.iloc[test_idx]\n",
                "\n",
                "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preprocessing & Reshaping\n",
                "Standardize, then reshape to `(N, 13, 1)`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_val_scaled = scaler.transform(X_val)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "# Reshape for LSTM: (Samples, Timesteps, Features)\n",
                "# Here Timesteps=13 (coefficients), Features=1\n",
                "X_train_lstm = X_train_scaled.reshape(X_train_scaled.shape[0], 13, 1)\n",
                "X_val_lstm = X_val_scaled.reshape(X_val_scaled.shape[0], 13, 1)\n",
                "X_test_lstm = X_test_scaled.reshape(X_test_scaled.shape[0], 13, 1)\n",
                "\n",
                "print(f\"LSTM Input Shape: {X_train_lstm.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Build Model (Kaggle Architecture)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_kaggle_lstm_model(input_shape, num_classes):\n",
                "    model = Sequential()\n",
                "    \n",
                "    # 1st LSTM Layer\n",
                "    model.add(LSTM(64, input_shape=input_shape, return_sequences=True))\n",
                "    \n",
                "    # 2nd LSTM Layer\n",
                "    model.add(LSTM(64))\n",
                "    \n",
                "    # Dense Layer\n",
                "    model.add(Dense(64, activation='relu'))\n",
                "    \n",
                "    # Dropout\n",
                "    model.add(Dropout(0.3))\n",
                "    \n",
                "    # Output Layer\n",
                "    model.add(Dense(num_classes, activation='softmax'))\n",
                "    \n",
                "    model.compile(\n",
                "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
                "        loss='categorical_crossentropy',\n",
                "        metrics=['accuracy']\n",
                "    )\n",
                "    \n",
                "    return model\n",
                "\n",
                "model = build_kaggle_lstm_model((13, 1), num_classes)\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "callbacks = [\n",
                "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
                "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
                "]\n",
                "\n",
                "history = model.fit(\n",
                "    X_train_lstm, y_train,\n",
                "    validation_data=(X_val_lstm, y_val),\n",
                "    epochs=50,\n",
                "    batch_size=32,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Segment-level evaluation\n",
                "test_loss, test_acc = model.evaluate(X_test_lstm, y_test, verbose=0)\n",
                "print(f\"Segment Test Accuracy: {test_acc*100:.2f}%\")\n",
                "\n",
                "# Plot history\n",
                "plt.plot(history.history['accuracy'], label='Train')\n",
                "plt.plot(history.history['val_accuracy'], label='Val')\n",
                "plt.title('Accuracy')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# Song-level evaluation\n",
                "y_pred_prob = model.predict(X_test_lstm)\n",
                "y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
                "y_true_classes = np.argmax(y_test, axis=1)\n",
                "\n",
                "results_df = pd.DataFrame({\n",
                "    'song_id': groups_test.values,\n",
                "    'true_label': y_true_classes,\n",
                "    'pred_label': y_pred_classes\n",
                "})\n",
                "\n",
                "song_results = results_df.groupby('song_id').agg(lambda x: x.mode()[0])\n",
                "song_acc = accuracy_score(song_results['true_label'], song_results['pred_label'])\n",
                "\n",
                "print(f\"\\nSong-Level Accuracy: {song_acc*100:.2f}%\")\n",
                "print(classification_report(song_results['true_label'], song_results['pred_label'], target_names=label_encoder.classes_))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}