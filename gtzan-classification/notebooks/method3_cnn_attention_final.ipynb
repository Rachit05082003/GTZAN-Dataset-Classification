{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Method 3: CNN with Multi-Head Attention (Fixed)\n",
                "\n",
                "**Goal:** Train a high-accuracy music genre classifier using a Convolutional Neural Network (CNN) enhanced with Multi-Head Attention.\n",
                "\n",
                "**Key Innovations:**\n",
                "- **Data Augmentation**: Increases training data size using time stretching, pitch shifting, and noise injection to combat overfitting on the small GTZAN dataset.\n",
                "- **Segment-based Processing**: Splits each song into 10 temporal segments. A shared CNN processes each segment independently (TimeDistributed).\n",
                "- **Multi-Head Attention**: Aggregates information from all segments, allowing the model to weigh the importance of different parts of the song dynamically.\n",
                "- **Label Smoothing**: Regularization technique to prevent the model from becoming too confident in its predictions."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Imports & Configuration\n",
                "**Description:** Import necessary libraries and set hyperparameters. \n",
                "- `N_MELS = 64`: Number of Mel bands (smaller than Method 1/2 to reduce dimensionality for attention).\n",
                "- `NUM_SEGMENTS = 10`: Number of chunks each 30s audio file is split into.\n",
                "\n",
                "**Outputs:**\n",
                "- Libraries loaded\n",
                "- TensorFlow version printed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import librosa\n",
                "import os\n",
                "import random\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers, Model, regularizers\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Seeds for reproducibility\n",
                "SEED = 42\n",
                "np.random.seed(SEED)\n",
                "tf.random.set_seed(SEED)\n",
                "random.seed(SEED)\n",
                "\n",
                "# Config\n",
                "SAMPLE_RATE = 22050\n",
                "DURATION = 30\n",
                "N_MELS = 64\n",
                "N_FFT = 2048\n",
                "HOP_LENGTH = 512\n",
                "NUM_SEGMENTS = 10\n",
                "NUM_CLASSES = 10\n",
                "\n",
                "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop',\n",
                "          'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
                "\n",
                "DATA_PATH = '../data/gtzan/genres_original'\n",
                "OUTPUT_DIR = '../models'\n",
                "if not os.path.exists(OUTPUT_DIR):\n",
                "    os.makedirs(OUTPUT_DIR)\n",
                "\n",
                "print(f'TensorFlow: {tf.__version__}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Augmentation\n",
                "**Description:** Define transformations to artificially expand the dataset.\n",
                "- **Time Stretch**: Changes speed without changing pitch.\n",
                "- **Pitch Shift**: Changes pitch without changing speed.\n",
                "- **Noise Injection**: Adds random Gaussian noise.\n",
                "\n",
                "**Returns:** \n",
                "- List containing original audio plus augmented versions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def augment_audio(y, sr):\n",
                "    \"\"\"Apply audio augmentations to increase training data.\"\"\"\n",
                "    augmented = [y]  # Original\n",
                "    \n",
                "    # Time stretch\n",
                "    rate = np.random.uniform(0.9, 1.1)\n",
                "    y_stretch = librosa.effects.time_stretch(y, rate=rate)\n",
                "    # Fix length after stretching\n",
                "    if len(y_stretch) > len(y):\n",
                "        y_stretch = y_stretch[:len(y)]\n",
                "    else:\n",
                "        y_stretch = np.pad(y_stretch, (0, len(y) - len(y_stretch)))\n",
                "    augmented.append(y_stretch)\n",
                "    \n",
                "    # Pitch shift\n",
                "    n_steps = np.random.randint(-2, 3)\n",
                "    if n_steps != 0:\n",
                "        y_pitch = librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n",
                "        augmented.append(y_pitch)\n",
                "    \n",
                "    # Add noise\n",
                "    noise = np.random.normal(0, 0.003, len(y))\n",
                "    augmented.append(y + noise)\n",
                "    \n",
                "    return augmented\n",
                "\n",
                "print('Augmentation functions defined')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Extraction\n",
                "**Description:** \n",
                "1. Compute Mel Spectrogram for the entire 30s clip.\n",
                "2. Split the spectrogram into `NUM_SEGMENTS` equal parts.\n",
                "\n",
                "**Inputs:**\n",
                "- Raw audio array\n",
                "\n",
                "**Outputs:**\n",
                "- 3D array: `(num_segments, n_mels, time_bins_per_segment)`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_segmented_melspec(y, sr, num_segments=NUM_SEGMENTS):\n",
                "    \"\"\"Extract mel-spectrogram and segment into parts.\"\"\"\n",
                "    # Full mel-spectrogram\n",
                "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS, \n",
                "                                          n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
                "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
                "    \n",
                "    # Segment into equal parts\n",
                "    total_frames = mel_db.shape[1]\n",
                "    segment_len = total_frames // num_segments\n",
                "    \n",
                "    segments = []\n",
                "    for i in range(num_segments):\n",
                "        start = i * segment_len\n",
                "        end = start + segment_len\n",
                "        seg = mel_db[:, start:end]\n",
                "        segments.append(seg)\n",
                "    \n",
                "    return np.array(segments)  # (10, 64, segment_len)\n",
                "\n",
                "print('Feature extraction defined')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load & Process Dataset\n",
                "**Description:** Iterate through genres, load audio, apply augmentation, and extract segmental features for every file. This significantly increases the effective dataset size (approx 4x).\n",
                "\n",
                "**Outputs:**\n",
                "- `X`: Features array\n",
                "- `y`: Labels array"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_dataset(data_path, augment=True):\n",
                "    \"\"\"Load GTZAN with optional augmentation.\"\"\"\n",
                "    X, y = [], []\n",
                "    \n",
                "    for genre in GENRES:\n",
                "        genre_path = os.path.join(data_path, genre)\n",
                "        if not os.path.exists(genre_path):\n",
                "            continue\n",
                "        \n",
                "        files = sorted([f for f in os.listdir(genre_path) if f.endswith('.wav')])\n",
                "        if 'jazz.00054.wav' in files:\n",
                "             files.remove('jazz.00054.wav') # Corrupt file\n",
                "\n",
                "        print(f'{genre}: {len(files)} files')\n",
                "        \n",
                "        for f in files:\n",
                "            try:\n",
                "                filepath = os.path.join(genre_path, f)\n",
                "                audio, sr = librosa.load(filepath, sr=SAMPLE_RATE, duration=DURATION)\n",
                "                \n",
                "                # Pad/trim to exact length\n",
                "                target_len = SAMPLE_RATE * DURATION\n",
                "                if len(audio) < target_len:\n",
                "                    audio = np.pad(audio, (0, target_len - len(audio)))\n",
                "                else:\n",
                "                    audio = audio[:target_len]\n",
                "                \n",
                "                # Get audio versions (original + augmented)\n",
                "                if augment:\n",
                "                    audio_versions = augment_audio(audio, sr)\n",
                "                else:\n",
                "                    audio_versions = [audio]\n",
                "                \n",
                "                for av in audio_versions:\n",
                "                    features = extract_segmented_melspec(av, sr)\n",
                "                    X.append(features)\n",
                "                    y.append(genre)\n",
                "                    \n",
                "            except Exception as e:\n",
                "                print(f'Error: {f}: {e}')\n",
                "    \n",
                "    return np.array(X), np.array(y)\n",
                "\n",
                "print('Loading dataset with augmentation...')\n",
                "X, y = load_dataset(DATA_PATH, augment=True)\n",
                "print(f'\\nTotal samples: {len(X)}')\n",
                "print(f'Shape: {X.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Split and Normalize\n",
                "**Description:** \n",
                "- Encode string labels to integers.\n",
                "- stratified Train/Val/Test split.\n",
                "- **Normalization:** Standard scaling `(X - mean) / std` using training set statistics.\n",
                "- **Label Smoothing:** Applied to `to_categorical` (though standard keras `to_categorical` doesn't support smoothing directly, so we might implement it in the loss or just use soft targets if manually implemented. **Note:** In this code block, `to_categorical` is used simply. Label smoothing will actually be handled by the loss function if `label_smoothing` argument is used in `categorical_crossentropy` or if we manually smoothed labels—wait, checking the code—the code uses `loss='categorical_crossentropy'` later. If `label_smoothing` isn't in compile, it's just standard One-Hot. Let's start with standard execution).\n",
                "\n",
                "**Outputs:**\n",
                "- Normalized `X_train`, `X_val`, `X_test`\n",
                "- `mean`, `std` (to be saved later)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encode labels\n",
                "le = LabelEncoder()\n",
                "y_enc = le.fit_transform(y)\n",
                "\n",
                "# Split: 80/10/10\n",
                "X_temp, X_test, y_temp, y_test = train_test_split(\n",
                "    X, y_enc, test_size=0.1, stratify=y_enc, random_state=SEED)\n",
                "X_train, X_val, y_train, y_val = train_test_split(\n",
                "    X_temp, y_temp, test_size=0.111, stratify=y_temp, random_state=SEED)\n",
                "\n",
                "# Normalize\n",
                "mean = X_train.mean()\n",
                "std = X_train.std()\n",
                "X_train = (X_train - mean) / (std + 1e-8)\n",
                "X_val = (X_val - mean) / (std + 1e-8)\n",
                "X_test = (X_test - mean) / (std + 1e-8)\n",
                "\n",
                "# Add channel dim -> (batch, segments, mels, time, 1)\n",
                "X_train = X_train[..., np.newaxis]\n",
                "X_val = X_val[..., np.newaxis]\n",
                "X_test = X_test[..., np.newaxis]\n",
                "\n",
                "# One-hot\n",
                "y_train_cat = to_categorical(y_train, NUM_CLASSES)\n",
                "y_val_cat = to_categorical(y_val, NUM_CLASSES)\n",
                "y_test_cat = to_categorical(y_test, NUM_CLASSES)\n",
                "\n",
                "print(f'Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Custom Multi-Head Attention\n",
                "**Description:** A custom Keras layer implementing Scaled Dot-Product Attention with multiple heads. \n",
                "- `split_heads`: Divides the query/key/value vectors into multiple heads.\n",
                "- `call`: Computes attention scores and weighted sum of values.\n",
                "\n",
                "**Why?** Allows the model to focus on the most characteristic segments of a song (e.g., the chorus or a solo) rather than treating all parts equally."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MultiHeadAttention(layers.Layer):\n",
                "    \"\"\"Simplified Multi-Head Attention for small datasets.\"\"\"\n",
                "    \n",
                "    def __init__(self, d_model=64, num_heads=4, dropout_rate=0.1, **kwargs):\n",
                "        super().__init__(**kwargs)\n",
                "        self.d_model = d_model\n",
                "        self.num_heads = num_heads\n",
                "        self.depth = d_model // num_heads\n",
                "        self.dropout_rate = dropout_rate\n",
                "        \n",
                "        self.wq = layers.Dense(d_model)\n",
                "        self.wk = layers.Dense(d_model)\n",
                "        self.wv = layers.Dense(d_model)\n",
                "        self.dense = layers.Dense(d_model)\n",
                "        self.dropout = layers.Dropout(dropout_rate)\n",
                "    \n",
                "    def split_heads(self, x, batch_size):\n",
                "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
                "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
                "    \n",
                "    def call(self, inputs, training=False):\n",
                "        batch_size = tf.shape(inputs)[0]\n",
                "        \n",
                "        q = self.split_heads(self.wq(inputs), batch_size)\n",
                "        k = self.split_heads(self.wk(inputs), batch_size)\n",
                "        v = self.split_heads(self.wv(inputs), batch_size)\n",
                "        \n",
                "        scale = tf.math.sqrt(tf.cast(self.depth, tf.float32))\n",
                "        attention = tf.nn.softmax(tf.matmul(q, k, transpose_b=True) / scale, axis=-1)\n",
                "        attention = self.dropout(attention, training=training)\n",
                "        \n",
                "        out = tf.matmul(attention, v)\n",
                "        out = tf.transpose(out, perm=[0, 2, 1, 3])\n",
                "        out = tf.reshape(out, (batch_size, -1, self.d_model))\n",
                "        \n",
                "        return self.dense(out)\n",
                "\n",
                "print('MultiHeadAttention defined: 4 heads, 64 dimensions')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Build Model Architecture\n",
                "**Structure:**\n",
                "1.  **Input:** `(10, 64, 129, 1)` - 10 segments of spectrogram images.\n",
                "2.  **TimeDistributed CNN:** A simpler CNN (2 blocks) is applied to *each segment independently*. This extracts a feature vector for every segment.\n",
                "3.  **Multi-Head Attention:** Processes the sequence of 10 feature vectors.\n",
                "4.  **Global Pooling:** Averages the attention outputs over time.\n",
                "5.  **Classifier:** Dense layer with Dropout and Softmax.\n",
                "\n",
                "**Outputs:**\n",
                "- Compiled Keras model summary."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_segment_cnn(input_shape):\n",
                "    \"\"\"CNN for each segment - smaller architecture.\"\"\"\n",
                "    inputs = layers.Input(shape=input_shape)\n",
                "    \n",
                "    x = layers.Conv2D(32, (3,3), padding='same')(inputs)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    x = layers.Activation('relu')(x)\n",
                "    x = layers.MaxPooling2D((2,2))(x)\n",
                "    \n",
                "    x = layers.Conv2D(64, (3,3), padding='same')(x)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    x = layers.Activation('relu')(x)\n",
                "    x = layers.MaxPooling2D((2,2))(x)\n",
                "    \n",
                "    x = layers.GlobalAveragePooling2D()(x)\n",
                "    \n",
                "    return Model(inputs, x, name='segment_cnn')\n",
                "\n",
                "def build_model(segment_shape):\n",
                "    \"\"\"Full model with multi-head attention.\"\"\"\n",
                "    inputs = layers.Input(shape=(NUM_SEGMENTS,) + segment_shape)\n",
                "    \n",
                "    # CNN per segment\n",
                "    cnn = build_segment_cnn(segment_shape)\n",
                "    x = layers.TimeDistributed(cnn)(inputs)  # (batch, 10, 64)\n",
                "    \n",
                "    # Multi-head attention\n",
                "    x = MultiHeadAttention(d_model=64, num_heads=4, dropout_rate=0.2)(x)\n",
                "    \n",
                "    # Pool over time\n",
                "    x = layers.GlobalAveragePooling1D()(x)\n",
                "    \n",
                "    # Classifier\n",
                "    x = layers.Dense(64, activation='relu')(x)\n",
                "    x = layers.Dropout(0.5)(x)\n",
                "    outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
                "    \n",
                "    model = Model(inputs, outputs)\n",
                "    \n",
                "    # Use label smoothing in loss if possible, or manual. Here using standard cat_cross.\n",
                "    # Note: To apply label smoothing in TF < 2.2, one would implement a custom loss.\n",
                "    # For simplicity, we use standard loss as placeholder or built-in if version supports.\n",
                "    # TF 2.x supports label_smoothing argument in Loss class.\n",
                "    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
                "    \n",
                "    model.compile(\n",
                "        optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
                "        loss=loss,\n",
                "        metrics=['accuracy']\n",
                "    )\n",
                "    \n",
                "    return model\n",
                "\n",
                "# Build\n",
                "segment_shape = X_train.shape[2:]  # (64, seg_len, 1)\n",
                "model = build_model(segment_shape)\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Training\n",
                "**Description:** Train the model with careful regularization mechanics:\n",
                "- **EarlyStopping:** Stops if validation accuracy doesn't improve for 20 epochs.\n",
                "- **ReduceLROnPlateau:** Lowers learning rate if progress stalls.\n",
                "- **Epochs:** 100 (stopped early usually).\n",
                "\n",
                "**Outputs:**\n",
                "- Training logs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "callbacks = [\n",
                "    EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True),\n",
                "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-6)\n",
                "]\n",
                "\n",
                "history = model.fit(\n",
                "    X_train, y_train_cat,\n",
                "    validation_data=(X_val, y_val_cat),\n",
                "    epochs=100,\n",
                "    batch_size=32,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Evaluation\n",
                "**Description:** Assess model performance on the unseen test set.\n",
                "\n",
                "**Outputs:**\n",
                "- Accuracy/Loss Plots\n",
                "- Test Accuracy Score\n",
                "- Classification Report (Precision, Recall, F1-Score per genre)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot accuracy/loss\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "axes[0].plot(history.history['accuracy'], label='Train')\n",
                "axes[0].plot(history.history['val_accuracy'], label='Val')\n",
                "axes[0].set_title('Accuracy')\n",
                "axes[0].legend()\n",
                "\n",
                "axes[1].plot(history.history['loss'], label='Train')\n",
                "axes[1].plot(history.history['val_loss'], label='Val')\n",
                "axes[1].set_title('Loss')\n",
                "axes[1].legend()\n",
                "plt.show()\n",
                "\n",
                "# Test Eval\n",
                "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
                "print(f\"\\nTest Accuracy: {test_acc*100:.2f}%\")\n",
                "\n",
                "y_pred = model.predict(X_test)\n",
                "y_pred_classes = np.argmax(y_pred, axis=1)\n",
                "\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_test, y_pred_classes, target_names=le.classes_))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Description:** Assess model performance on the unseen test set.\n",
                "\n",
                "**Outputs:**\n",
                "- Accuracy/Loss Plots\n",
                "- Test Accuracy Score\n",
                "- Classification Report (Precision, Recall, F1-Score per genre)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.save(f'{OUTPUT_DIR}/method3_attention.keras')\n",
                "np.savez(f'{OUTPUT_DIR}/method3_scalars.npz', mean=mean, std=std)\n",
                "print(\"Model and scalars saved.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "gtzan",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.25"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
