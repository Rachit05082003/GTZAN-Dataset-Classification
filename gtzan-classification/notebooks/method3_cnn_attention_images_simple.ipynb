{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CNN + Attention: Images Only (Optimized)\n",
                "\n",
                "Simple and optimized model using only spectrogram images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
                "\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, Model\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from tqdm import tqdm\n",
                "\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "print(f\"TensorFlow: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== CONFIG ====================\n",
                "IMAGE_PATH = '/Users/narac0503/GIT/GTZAN Dataset Classification/GTZAN-Dataset-Classification/gtzan-classification/data/gtzan/images_original'\n",
                "TARGET_SIZE = (128, 128)\n",
                "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
                "NUM_CLASSES = 10\n",
                "\n",
                "print(f\"Path exists: {os.path.exists(IMAGE_PATH)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== LOAD IMAGES ====================\n",
                "X, y = [], []\n",
                "\n",
                "print(\"Loading images...\\n\")\n",
                "for genre in GENRES:\n",
                "    genre_path = os.path.join(IMAGE_PATH, genre)\n",
                "    if not os.path.exists(genre_path):\n",
                "        print(f\"{genre}: NOT FOUND\")\n",
                "        continue\n",
                "    \n",
                "    files = [f for f in os.listdir(genre_path) if f.endswith('.png')]\n",
                "    print(f\"{genre}: {len(files)} images\")\n",
                "    \n",
                "    for f in tqdm(files, desc=genre):\n",
                "        try:\n",
                "            img = Image.open(os.path.join(genre_path, f))\n",
                "            img = img.convert('RGB').resize(TARGET_SIZE)\n",
                "            X.append(np.array(img) / 255.0)\n",
                "            y.append(genre)\n",
                "        except:\n",
                "            pass\n",
                "\n",
                "X = np.array(X)\n",
                "y = np.array(y)\n",
                "print(f\"\\nLoaded: {X.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== PREPROCESS ====================\n",
                "le = LabelEncoder()\n",
                "y_enc = le.fit_transform(y)\n",
                "y_cat = to_categorical(y_enc, NUM_CLASSES)\n",
                "\n",
                "# Normalize images\n",
                "X = (X - X.mean()) / (X.std() + 1e-8)\n",
                "print(f\"Normalized - Mean: {X.mean():.4f}, Std: {X.std():.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== SPLIT ====================\n",
                "X_temp, X_test, y_temp, y_test = train_test_split(\n",
                "    X, y_cat, test_size=0.1, stratify=y_enc, random_state=42\n",
                ")\n",
                "X_train, X_val, y_train, y_val = train_test_split(\n",
                "    X_temp, y_temp, test_size=0.111, stratify=np.argmax(y_temp, 1), random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Train: {len(X_train)}\")\n",
                "print(f\"Val: {len(X_val)}\")\n",
                "print(f\"Test: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== BUILD MODEL ====================\n",
                "inputs = layers.Input(shape=(128, 128, 3))\n",
                "x = inputs\n",
                "\n",
                "# CNN blocks\n",
                "for filters in [32, 64, 128, 256]:\n",
                "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    x = layers.Activation('relu')(x)\n",
                "    x = layers.MaxPooling2D(2)(x)\n",
                "    x = layers.Dropout(0.25)(x)\n",
                "\n",
                "# Reshape for attention\n",
                "x = layers.Reshape((-1, 256))(x)\n",
                "\n",
                "# Multi-head attention\n",
                "x = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
                "x = layers.GlobalAveragePooling1D()(x)\n",
                "\n",
                "# Classifier\n",
                "x = layers.Dense(256, activation='relu')(x)\n",
                "x = layers.Dropout(0.4)(x)\n",
                "x = layers.Dense(128, activation='relu')(x)\n",
                "x = layers.Dropout(0.3)(x)\n",
                "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
                "\n",
                "model = Model(inputs, outputs)\n",
                "\n",
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
                "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== TRAIN ====================\n",
                "callbacks = [\n",
                "    EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, verbose=1),\n",
                "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7, verbose=1),\n",
                "    ModelCheckpoint('best_cnn_attention.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
                "]\n",
                "\n",
                "history = model.fit(\n",
                "    X_train, y_train,\n",
                "    validation_data=(X_val, y_val),\n",
                "    batch_size=16,\n",
                "    epochs=100,\n",
                "    callbacks=callbacks\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== PLOT ====================\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "ax1.plot(history.history['accuracy'], label='Train')\n",
                "ax1.plot(history.history['val_accuracy'], label='Val')\n",
                "ax1.set_title('Accuracy')\n",
                "ax1.legend()\n",
                "\n",
                "ax2.plot(history.history['loss'], label='Train')\n",
                "ax2.plot(history.history['val_loss'], label='Val')\n",
                "ax2.set_title('Loss')\n",
                "ax2.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== EVALUATE ====================\n",
                "model.load_weights('best_cnn_attention.keras')\n",
                "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
                "\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(f\"TEST ACCURACY: {acc*100:.2f}%\")\n",
                "print(f\"TEST LOSS: {loss:.4f}\")\n",
                "print(f\"{'='*50}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== RESULTS ====================\n",
                "y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
                "y_true = np.argmax(y_test, axis=1)\n",
                "\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_true, y_pred, target_names=GENRES))\n",
                "\n",
                "# Confusion matrix\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "            xticklabels=GENRES, yticklabels=GENRES)\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('True')\n",
                "plt.title(f'Confusion Matrix (Acc: {acc:.2%})')\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== SAVE ====================\n",
                "model.save('cnn_attention_images_final.keras')\n",
                "print(\"Model saved!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "gtzan",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.25"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}